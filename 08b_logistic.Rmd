# Multinomial Logistic Regression

## Objectives 

At the end of this chapter, readers should be able:

1.  to understand the concept of logistic regression model to analyze data with polychotomous (multinomial) outcome
2.  to estimate parameters of interest in a logistic regression model from data with polychotomous (multinomial) outcome
3.  to make inference based on a logistic regression model from data with polychotomous (multinomial) outcome
4.  to predict the outcome based on a logistic regression model from data with polychotomous (multinomial) outcome
5.  to perform model checking of logistic regression model from data with with polychotomous (multinomial) outcomes

## Introduction

Some data come with multinomial outcomes in which case, the outcome variable is a nominal or polychotomous variable with more than two levels. In multinomial outcome data, the outcome has no natural ordering. if it has, then it is best treated as a ordinal outcome data. For these data, we can modify the binary logistic model to make estimation and inference [@kleinbaum2010logistic ; @Hosmer2013-03-22]. 



Variables with more than two levels are known as either:

1.  multinomial data\index{Multinomial data}
2.  polychotomous data\index{Polychotomous data}
3.  polytomous data\index{Polytomous data}

If we employ logistic regression to such data, then the analysis is known as polytomous or multinomial logistic regression. Again, the polychotomous outcome does not have any natural order. When the categories of the outcome variable do have a natural order, ordinal logistic regression\index{Ordinal logistic regression} is preferred. 


## Examples of multinomial outcome variables\index{Multinomial outcome variable} 

Examples of data with polychotomous outcome variables\index{Polychotomous outcome variable} (with more than two levels) include:

1.  disease symptoms that have been classified by subjects as being absent, mild, moderate, or severe,
2.  tumour invasiveness  classified as in situ, locally invasive, ormetastatic, or
3.  patient preferred treatment regimen,  selected from among three or more options for example oral medication only, oral medication plus  injection medication or injection only.

A numerical outcome can be categorized based on different cut-off points. The newly created categorical variable is now either treated as a nominal or polychotomous or multinomial outcome  or as a ordinal outcome. That justifies the use of multinomial logistic regression. 

## Models for multinomial outcome data

With a multinomial outcome data, an extension of logistic regression know as multinomial logit or multinomial logistic regression can be performed. In multinomial logistic regression, one of the categories of the outcome variable is designated as the reference category and each of the other levels is compared with this reference. The choice of reference category can be arbitrary and is at the discretion of the researcher. Most software set the first category as the reference (also known as the baseline category) by default.

Other models that can analyze data with polychotomous outcome include:

1. Stereotype logistic regression - each independent variable has one value for each individual
2. Alternative-specific variables  


## Estimation for Multinomial logit model\index{Multinomial logit model}

Remember, interpreting and assessing the significance of the estimated coefficients are the main objectives in regression analysis. in multinomial logistic regression, we would like to model the relationship between covariates with the outcome variable that has more than two categories but without ordering or ranking. 

The actual values taken by the dependent variable are irrelevant. In Stata\index{STATA}, the **exponentiated beta** $\exp^{\beta}$ will generate the so-called the **relative-risk ratio**\index{Relative-risk ratio}. The dependent variable again, is a discrete variable and the model is estimated using maximum likelihood.

In multinomial logistic regression for example in data with three categories of the outcome, the sum of the probabilities for the three outcome categories must be equal to 1 (the total probability). The comparison is done between two categories each time. Because of that, each comparison considers only two probabilities, and the probabilities in the ratio do not sum to 1. Thus, the two odds-like expressions in multinomial logistic regression are not true odds.

Multinomial logistic regression can be thought as of simultenously fitting binary logits for all comparisons among the alternatives.

### Log Odds\index{Log odds} and Odds Ratios\index{Odds ratio}

In the special case where the covariate is binary, coded 0 or 1, we simplify the notation to $OR_j = OR_j(1,0)$. Let use an example where data have 3 categories of outcome; 0,1 and 2. 

Let's say we have a dataset with the outcome variable, $Y$, and is coded as $0, 1,$ or $2$. In practice one should check that the software package that is going to be used allows a $0$ code as the smallest category. We have used packages that require that the codes begin with $1$.

SO the logit functions (log odds\index{Log odds}) when the outcome is a D variable with (0,1 and 2 values) are as below

1.  the log odds\index{Log odds} for comparison between 0 and 1 is

$$g_1(x) = ln\frac{P(D=1|X_1)} {P(D=0|X_1)}=\alpha_1 + (\beta_{11}X_1)$$

2.  and, the log odds\index{Log odds} for comparison between 0 and 2 is

$$g_2(x) =  ln\frac{P(D=2|X_1)} {P(D=0|X_1)}=\alpha_2 + (\beta_{21}X_1)$$

If for example, we assume that the outcome labelled with $Y=0$ is the reference outcome. The subscript on the odds ratio\index{Odds ratio} indicates which outcome is being compared to the reference category outcome. The odds ratio\index{Odds ratio} of outcome $Y = j$ versus $Y = 0$ for the covariate values of $x = a$ versus $x = b$ is:

$$OR_{j}(a,b)= \frac{Pr(Y=j|x=a)/(Pr(Y=0|x=a)} {Pr(Y=j|x=b)/Pr(Y=0|x=b)}$$

Each odds ratio\index{Odds ratio} is calculated in a manner similar to that used in standard logistic regression. That is:

$$OR_1(X=1,X=0)= \frac{Pr(D=1|X=1)/(Pr(D=0|X=1)} {Pr(Y=1|X=0)/Pr(D=0|X=0)}=\exp^{\beta_{11}}$$

$$OR_2(X=2,X=0)= \frac{Pr(D=2|X=1)/(Pr(D=0|X=1)} {Pr(D=2|X=0)/Pr(D=0|X=0)}=\exp^{\beta_{21}}$$

### Conditional probabilities\index{Conditional probabilities}

The conditional probabilities\index{Conditional probabilities} for the multinomial logit model\index{Multinomial logit model} are: 

$$Pr(D = 0 | x) = \frac{1}{1+e^{g_1(x)} + e^{g_2(x)}}$$

$$Pr(D = 1 | x) = \frac{e^{g_1(x)}}{1+e^{g_1(x)} + e^{g_2(x)}}$$

$$Pr(D = 2 | x) = \frac{e^{g_2(x)}}{1+e^{g_1(x)} + e^{g_2(x)}}$$


## Prepare environment

Start brand new analysis with a new project in RStudio 

### Loading libraries

- the general packages libraries

```{r}
library(here)
library(tidyverse)
library(haven)
library(gtsummary)
```

### Dataset

The dataset we are going to use comes from the low birth weight dataset. The dataset can be loaded from **aplore3**aplore3 package. In this chapter, we have categorized variable low from a numerical variable to a categorical variable. 


- me: the outcome variable is mammography experience (0 = never, 1 = within a year, 2 = over a year ago)
-  sympt: "You do not need a mamogram unless you develop symptoms". Codes are, 1 = Strongly Agree, 2 = Agree, 3 = Disagree, 4 = Strongly Disagree
-  pb: Perceived benefit of mammography. Score between 5 - 20 
-  HIST: Mother or Sister with a history of breast cancer. Codes are 0 = No, 1 = Yes 
-  bse: "Has anyone taught you how to examine your own breasts: that is BSE". Codes are 0 = No, 1 = Yes
-  detc: "How likely is it that a mamogram could find a new case of breast cancer". Codes are 1= Not likely, 2 = Somewhat likely, 3 = Very likely

### Read data

We will use `haven::read_dta()`\index{haven} function to read stata\index{STATA} `.dta` data into the memory. Remember, we can also use `foreign::read.dta()`\index{foreign} function to read stata\index{STATA} `.dta` data. It is your choice.  

We use `here()` to indicate that the folder `data` contains the dataset `mammog9.dta` 


```{r}
dat.m1 <- read_dta(here('data','mammog9.dta'))
```

We can then quickly check types variables


```{r}
glimpse(dat.m1)
```

Next, is to return the table of summary statistics 

```{r}
tbl_summary(dat.m1)
```

We will create a new variable `me2`, then we will check the categories of the variable `me2` to ensure it validly mirror variable `me`

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(me2 = 
           factor(me, 
                  labels =   c("never","within.a.year","over.a.year.ago")))
```


```{r}
dat.m1 %>% 
  count(me2)
```

We will do the same thing to variable `hist`:

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(hist2 = factor(hist,
                        labels = c("no","yes")))
```

```{r}
dat.m1 %>% 
  count(hist2)
```

We can now generate a table of summary statistics based on categories of `me2`. The summary statistics for numerical variables will be mean and SD. 

```{r}
dat.m1 %>%
  select(-me, -hist) %>%
  tbl_summary(by = me2,
              statistic = list(all_continuous() ~ "{mean} ({sd})"))
```


## Univariable multinomial logistic regression 

We will use **VGAM**\index{VGAM} package and we need to reverse the levels for variable **me2** to replicate the outputs in Chapter 8 from tthe Applied Logistic Regression book [@Hosmer2013-03-22]. To do that, we make the group `never` (the last group) as the reference category.

The steps below:

- confirm the order of variable me2
- generate variable me3 that equals to me2
- change order of me3 from over a year to within a year to never
- confirm observations are still correct

```{r}
levels(dat.m1$me2)
```

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(me3 = fct_relevel(me2,
                       c("over.a.year.ago", 'within.a.year', 'never')))
table(dat.m1$me) ; summary(dat.m1$me2) ; summary(dat.m1$me3)
```

The function `VGAM::vglm()` runs the multinomial logistic regression. Using the `vglm()`A function we will estimate a multinomial logit model\index{Multinomial logit model} for 

1.  group 1 vs group 3 : over a year ago vs never did me
2.  group 2 vs group 3 : within a year ago vs never did me

So, the reference group is - again -  the *never* group. 

The steps we are taking are:

- Load the **VGAM**\index{VGAM} library
- Estimate the model and name the model object as `fitmlog1`
- Return the result of `fitmlog1`

```{r}
library(VGAM)
fitmlog1 <- vglm(me3 ~ hist2, multinomial, data = dat.m1)
summary(fitmlog1)
```

Be careful:

1.  (Intercept):1 for outcome me = over a year ago vs never
2.  (Intercept):2 for outcome me =  within a year vs never
3.  hist2yes:1 for outcome me = over a year ago vs never
4.  hist2yes:2 for outcome me =  within a year vs never

Next, we will convert `detc` to a new categorical variable `detc2`. 

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(detc2 = factor(detc))
```

We will fit the multinomial logit again (with covariate `detc2`) and name the model as `fitmlog2`. Remember, the comparisons are:

1.  group 1 vs group 3 : for outcome me = over a year ago vs never
2.  group 2 vs group 3 : for outcome me =  within a year vs never

```{r}
fitmlog2 <- vglm(me3 ~ detc2, multinomial, data = dat.m1)
summary(fitmlog2)
```

## Inferences

For the inference, we will:

1.  calculate the $95\%$ CI (interval estimates)
2.  calculate the p-values (hypothesis testing)

Because there is `broom::tidy()` for object with class vglm, we will use the codes below to produce a rather nice table:

1.  return the regression coefficents for all $\hat\beta$ as an object named `b_fitmlog2`
2.  return the the confidence intervals for all $\hat\beta$ as an object named `ci_fitmlog2` 
3.  combine the $\hat\beta$ and the corresponding $95\%$ CIs


```{r}
b_fitmlog2 <- coef(fitmlog2)
ci_fitmlog2 <- confint(fitmlog2)
b_ci_fitmlog2 <- cbind(b_fitmlog2, ci_fitmlog2)
b_ci_fitmlog2
```


Afterwards, we will *exponentiate* the coefficients to obtain the **relative-risk ratio**\index{Relative-risk ratio}. And combine the results to the previous table. Then we will name the columns of the object `tab_fitmlog2`. 

```{r}
rrr_fitmlog2 <- exp(b_ci_fitmlog2)
tab_fitmlog2 <- cbind(b_ci_fitmlog2, rrr_fitmlog2)
colnames(tab_fitmlog2) <- c('b', 'lower b', 'upper b', 
                            'rrr', 'lower rrr', 'upper rrr')
tab_fitmlog2
```

## Multivariable multinomial logistic regression\index{Multivariable multinomial logistic regression} 

We will add other covariates to our model and name the new (multivariable) model as `fitmlog3`. Using the `factor()` function, we  could easily convert the numeric variables (for example `sympt`) to a categorical variable.


```{r}
fitmlog3 <- vglm(me3 ~ factor(sympt) + pb + hist2 + bse + detc2,
                 multinomial, data = dat.m1)
summary(fitmlog3)
```

Variable **sympt** has 4 categories. To replicate the results as in Chapter 8 in Applied Logistic Regression book [@Hosmer2013-03-22], we recode **sympt** (4 categories) into 2 category factor variable **symptd**. This can be done using the `ifelse()` function

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(symptd = ifelse(sympt<3, '<3', '3 or more')) 
dat.m1 %>%  
  count(sympt,symptd)
```

Now, we refit the model and name the model as `fitmlog4`.

```{r}
fitmlog4 <- vglm(me3 ~ symptd + pb + hist2 + bse + detc2,
                 multinomial, data = dat.m1)
summary(fitmlog4)
```

## Inferences 

We could get the the confidence intervals and the p-values for each covariate. Then we will `cbind` (combine the columns) them together. 

```{r}
b_fitmlog4 <- coef(fitmlog4)
ci_fitmlog4 <- confint(fitmlog4)
cbind(b_fitmlog4, ci_fitmlog4)
```

As in the book, we will convert predictor variable `detc` (3 categories) to a binary category variable named as `detcd`. Then, we fit the model with covariate `detcd` and name the model as `fitmlog5`.

```{r}
dat.m1 <- 
  dat.m1 %>% 
  mutate(detcd = ifelse(detc<3, '<3', '3 or more'))
```

```{r}
fitmlog5 <- 
  vglm(me3 ~ symptd + pb + hist2 + bse + detcd,
                 multinomial, data = dat.m1)
summary(fitmlog5)
```

The sequence of codes below will:

1. return the log odds\index{Log odds} and the RRR 
2. return the $95\%$ CI for the log odds\index{Log odds} and the CI for RRR
3. combine the objects into a table
4. rename the columns


```{r}
b_rrr_fitmlog5 <- cbind(coef(fitmlog5), exp(coef(fitmlog5)))
ci_b_rrr.fitmlog5 <- cbind(confint(fitmlog5), exp(confint(fitmlog5)))
res_fitmlog5 <- cbind(b_rrr_fitmlog5, ci_b_rrr.fitmlog5)
colnames(res_fitmlog5) <- c('b', 'rrr', 
                            'lower 95% b','upper 95% b', 
                            'lower 95% rrr' , 'upper b95% rrr')
res_fitmlog5
```

## Interpretation

We will choose one numerical variable (`pb`) and one categorical variable (`hist`) for interpretation. 

For `pb`

- With one unit increase in score for `pb`, the relative rate (RR) ratio for doing me over a year ago change for a factor of 0.86 ($95\%$ CI 0.74 to 0.99, p-value = 0.033) or $14\%$ lower RR compared to never did me (when adjusting for other covariates)  
- With one unit increase in score for `pb`, the relative rate ratio for doing me within a year ago change for a factor of 0.78 ($95\%$ CI 0.68 to 0.90, p-value = $< 0.0001$) or $22\%$ lower RR compared to never did me (when adjusting for other covariates)

For `hist`

- Women with positive family history of breast cancer have 2.90 times the relative rate compared to women with no family history of breast cancer ($95\%$ CI 1.19 to 7.03) for doing me over a year ago than no me at all, when adjusting for other covariates (p-value 0.0189).   
- Women with positive family history of breast cancer have 3.71 times the relative rate compared to women with no family history of breast cancer ($95\%$ CI 1.21 to 8.67) for doing me within a year ago than no me at all, when adjusting for other covariates (p-value 0.003).

## Prediction

We can calculate the predicted probability of each category of outcome by using the `predict()` function. Below are the result for the top 10 observations. 

```{r}
predict.vgam(fitmlog5, type = 'response') %>% 
  head(10)
```

## Presentation of table of statistics 

We can make a *better* table using **knitr**\index{knitr} and **kableExtra**\index{kableExtra} packages

```{r}
library(knitr)
library(kableExtra)
kable(res_fitmlog5, digits = 3) %>%
  kable_styling(bootstrap_options = 
                  c("striped", "hover", "condensed", "responsive"))
```

