
# Survival Analysis 

## Introduction

Survival analysis is a common analysis in medicine. The dataset comes from a follow-up study either from a restrosprective or prospective study.

The survival analysis is also known as duration analysis or time-to-event analysis. Because sometime people confuse and wrongly think the survival analysis is only applicable to the study of survival (alive or death condition).

The survival or duration analysis is performed on data that has duration until an event occurs. Such dataset usually have a variable in the form of duration - the time variable - and another variable - the event variable - that is categorical.

The event can be of any interest, for example:

- relapse
- death
- recurrence 
- success

And variable time can be in any time form such as days, weeks, years or event minutes. If we combine them together then it can become:

- time to relapse
- time to death
- time to recurrence
- time to succed 

There are three types of survival analysis:

- the non-parametric survival analsysis
- the semi-parametric survival analysis
- the parametric survival analysis

At the beginning of the analysis, we usually perform the non-parametric analysis for example the Kaplan-Meier estimates. Following that, we will perform univariable or multivariable Cox proportional hazard (PH) regression model. If we are sure about the distribution of the risk, then we can proceed to parametric survival analysis.  

## Objectives 

The objective of the chapter is 

- to perform a non-parametric survival analysis that is the Kaplan-Meier survival analysis
- to perform the univariable semi-parametric survival model that's Cox proportional hazard regression analysis 
- to perform the multivariable Cox PH regression analysis 

## Prepare environment for analysis

Start a new analysis task by creating a new RStudio project. To do this,

1. Go to File
2. Click New Project
3. Choose New Directory or Existing Directory. This directory points to the folder that usually contains the dataset to be analyzed

Next, we will load the necessary packages. We will use 5 packages

## Load packages

To run the tutorial, we will use 

- **summarytools** package to give us quick descriptive statistics
- **tidyverse**: a package for data transformation
- **survival**: This is a package necessary to run survival analysis. There are other survival packages that can run survival analysis which you can find here <https://cran.r-project.org/web/views/Survival.html>
- **survminer**: a package to plot survival objects
- **pec**: a package to use a breast cancer dataset
- **broom**: to make prettier outputs
- **here** to manage location fo files

Remember, check if all packages are available in your R library. If you have not installed them, use `install.packages()` function to download and install the packages. 

Note: If or once the packages are already installed, then load the package

```{r}
library(summarytools)
library(tidyverse)
library(survival)
library(survminer)
library(pec)
library(broom)
library(here)
```


## Data

The tutorial uses a dataset named *stroke_dat* in the csv. These data come patients with stroke. We will look at  variables - at the time of admission - that may be prognostic of stroke deaths. 

The oucome of interest time from admission to death. These variables are codes as variable `time` and the event variable as `status`

Now let us load the data 

```{r}
stroke <- read_csv(here('data', 'stroke_data.csv'))
```

And take a peek at our data to check

- number of observations (n=219)
- name of variables (12 variables)
- type of variables (character and double)


```{r}
glimpse(stroke)
```

And the summary statistics are

```{r}
summary(stroke)
```


To be able to perform survival analysis, the dataset has to have a time-to-event variable

1.  time : a time variable indicates days taken from the first day the patient was enrolled in the study until the last seen  
2.  an event variable : a status variable for the patient when he or she was last seen  

So, it is a time-to-event dataset. There are other variables too for example

- sex:  
- referral: 
- dm:
- gcs:
- sbp:
- dbp: 
- wbc:
- str_type2:
- referral2:

In the dataset: 

1.  variable time *time* is a numeric variable measured in days
2.  variable event *event*  is a categorical variable coded as alive or dead


## Exploratory data   

The distribution of status at discharge

```{r}
stroke %>% group_by(status) %>% count()
```

The distribution of stroke types 

```{r}
stroke %>% group_by(status, stroke_type) %>% count()
```

The descriptive statistics for 

- the numerical variables

```{r}
stroke %>% descr()
```

- the categorical variable

```{r}
stroke %>% 
  dplyr::select(sex, dm, stroke_type, referral_from) %>%
  freq()
```



## Kaplan-Meier survival estimates 

### Estimate the KM survivals 


This is a non-parametric survival estimates. It provides the survival probability estimates at different time.  

## Survival probability

Kaplan-Meier (KM) is a non-parametric survival analysis. Using `survfit()`, we will estimate the survival probability using the Kaplan-Meier (KM) estimates. We will estimate KM for stroke types.  
And the result will be named `KM_str_type2`


```{r}
KM_str_type2 <- survfit(Surv(time = time2, event = status == "dead" ) ~ 
                          stroke_type, 
                        data = stroke)
summary(KM_str_type2)
```

## Plot the survival probability  

We will plot the survival probability based on the KM estimate.

The plot provides

1.  y axis: survival probability
2.  x axis: time

```{r}
ggsurvplot(KM_str_type2, data = stroke, risk.table = TRUE, 
           linetype = c(1,4), pval = TRUE)
```

Run the Kaplan-Meier estimates for variable dm and named the output as KM_dm

```{r}
KM_dm <- survfit(Surv(time = time2, event = status == "dead" ) ~ dm, 
                        data = stroke)
summary(KM_dm)
```

Plot the survival estimates

```{r}
ggsurvplot(KM_dm, data = stroke, risk.table = TRUE, 
           linetype = c(1,4), pval = TRUE)
```

## Comparing survival estimates from Kaplan-Meier analysis 

### Log-rank test

Plotting Kaplan-Meier survival curves provides graphical representation of survival probabilities in different group. 

The question is : Do the survival estimates differ between different levels (groups)?

To answer, we test the null hypothesis that the survival times between levels in variable *group* are similar.

A few available tests, for example:

1.  log-rank test (default)
2.  peto-peto test

```{r}
survdiff(Surv(time = time2, event = status == "dead") ~ stroke_type, 
         data = stroke)
```

The survival times between the stroke types *IS* and *HS* groups are different (p = 0.014). 

```{r}
survdiff(Surv(time = time2, event = status == "dead") ~ dm, data = stroke)
```

The survival times between the dm status *yes* and *no* groups are not different (p = 0.2). 

## Cox proportional hazard regression

### Advantages of Cox proportional hazard regression

The disadvantages of the Kaplan-Meier (KM) analysis include these:

1.  The need to categorize numerical variable
2.  It is a univariable analysis
3.  It is a non-parametric analysis


To overcome the limitations of the KM analysis, we can model our survival data using the semi-parametric **Cox proportional hazard regression**. 

We will use **Breast cancer survival data (GBSG2)** from **pec** package

Load the *GBSG2* data

```{r}
data(GBSG2)
```

Take a peek at data

```{r}
glimpse(GBSG2)
```

Get the summary statistics

```{r}
summary(GBSG2)
```

In the dataset (686 observations):

1.  the time variable: *time* (days)
2.  the event variable: *cens* (coded as 1 vs 0). The event of interest is 1 and censored cases (for example, loss to follow up) is 0. 

299 developed the event (n = 299)

```{r}
GBSG2 %>% count(cens)
```

Let us convert the `cens` (0 and 1) variable to 

1.  a variable named `event`
2.  and code *failed* for 1, and *censored* for 0

```{r}
GBSG2 <- GBSG2 %>% 
  mutate(event = factor(cens, 
                        labels =  c("censored", "failed")))
GBSG2 %>% count(event)
```


## Estimation of Cox proportional hazards regression

We will run a generalized linear model using Cox PH regression with

1.  time variable *time*
2.  event variable *event == "failed"*
3.  all covariates 

This becomes a multivariable Cox PH model


```{r}
GBSG2_coxph <- coxph(Surv(time = time, event = event == 'failed') ~ .,
                     data = GBSG2)
summary(GBSG2_coxph)
```

But for nicer output (in a data frame format), we can use `tidy()`. This will give us

- the estimate which is the log hazard. If you exponentiate it, you will get hazard ratio
- the standard error
- the p-value
- the confidence intervals for the log hazard

```{r}
tidy(GBSG2_coxph, conf.int = TRUE)
```

The results:

1.  The `coef` is the log hazard. 
2.  And the `exp(coef)` is hazard ratio. 

Interpretation: 

1.  Each 1 unit increase in **progrec**, the adjusted log hazard for dying change by -0.002. So, with 10 units increase in **progrec**, the adjusted log hazard for dying change by -0.02
2.  Each 1 unit increase in **progrec**, the adjusted rate for hazard or the risk for dying changed by 0.998. Or similarly, the risk for dying with 1 unit increase in **progrec**reduces by 0.2%.

## Inference from Cox proportional hazard regression

In inference, we assess the 

1.  the Wald test. This is shown with p-values in the example above
2.  the 95% confidence intervals for the log hazards

We can transform log hazard to hazard ratio by exp the $\hat\beta$. It is more interesting for applied scientists to make inferences based on the 95% CI of the hazard ratios.

This can be easily done using 

```{r}
tidy(GBSG2_coxph, exponentiate = TRUE, conf.int = TRUE)
```

This result implies that:

1.  patients treated with a hormonal therapy (`horThyes`) had a lower
risk ($29\%$ lower) to die. Thus they survived longer compared to women who were not treated this way, when adjusted for other covariates. 
2.  the risk for dying for patients treated with a hormonal therapy (`horThyes`) can be as small as $9\%$ or as big as $45\%$ at $95\%$ confidence levels, controlled for other covariates.  


## Prediction

We can predict

1.  the linear predictor
2.  the risk (risk score exp(lp))
3.  the he expected number of events given the covariates and follow-up time

```{r}
library(broom)
lp <- augment(GBSG2_coxph, data = GBSG2)
risks <- augment(GBSG2_coxph, data = GBSG2, type.predict = "risk")
expected <- augment(GBSG2_coxph, data = GBSG2, type.predict = "expected")
```

We can also plot the survival

```{r}
mod_coxph <- coxph(Surv(time = time, event = event == 'failed') ~ horTh + age + tgrade, data = GBSG2)
ggadjustedcurves(mod_coxph, data = GBSG2)
ggadjustedcurves(mod_coxph, data = GBSG2, variable = "horTh")
ggadjustedcurves(mod_coxph, data = GBSG2, method = "average", variable = "horTh")
```


## Checking the proportional hazard assumption

### Proportional hazard assumption

The most important assumption in Cox PH regression is the proportionality of the hazards over time.

A check of the proportional hazards assumption can be done by looking at the parameter estimates $\beta_1, ..., \beta_q$ over time. 

We can safely assume proportional hazards when the estimates don't vary much over time. 

The null hypothesis of constant regression coefficients can be tested, both globally as well as for each covariate, by using the cox.zph function.


```{r}
GBSG2_zph <- cox.zph(GBSG2_coxph)
GBSG2_zph
```

Evidence of time-varying effects (non-proportionality), especially for age (p = 0.0855)
and tumor grading. But we keep at this for now. Because this requires a more advanced method.

So basically, if the GLOBAL test gives non-significant (p> 0.05), the assumption of proportional hazard is met. if it is less than 0.05, we need to remedial measures. 

We can plot the log hazard over time, to see the performance of our model (in terms of proportionality)

```{r}
plot(GBSG2_zph, var = "age")
plot(GBSG2_zph, var = "tgrade")
plot(GBSG2_zph, var = "menostat")
plot(GBSG2_zph, var = "progrec")
plot(GBSG2_zph, var = "horTh")
```

For now, we will assume the proportionality of hazard is acceptable. In the case of serious violation of proportionality of hazard, we can remedy using 

1.  stratified cox regression
2.  extended cox regression using time-varying dependent variable
3.  parametric survival analysis


## References

1. Parts of this note are taken from this source  <http://ftp.auckland.ac.nz/software/CRAN/doc/vignettes/HSAUR/Ch_survival_analysis.pdf>. The source comes from the book entitled A Handbook of Statistical Analyses Using R - and if you are interested - the book can be bought here <https://www.amazon.com/Handbook-Statistical-Analyses-Using-Second/dp/1420079336>
