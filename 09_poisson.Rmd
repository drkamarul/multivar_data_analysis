# Poisson regression\index{Poisson regression}

## Objectives

After completing this chapter, the readers are expected to

- understand the basic concepts behind Poisson regression\index{Poisson regression} for count\index{Count data} and rate data\index{Rate data}
- perform Poisson regression\index{Poisson regression} for count and rate
- perform model fit\index{Model fit} assessment
- present and interpret the results of Poisson regression\index{Poisson regression} analyses

## Introduction

Poisson regression\index{Poisson regression} is a regression analysis for count\index{Count data} and rate data\index{Rate data}. As mentioned before in Chapter 7, it is is a type of Generalized linear models (GLMs)\index{Generalized linear model}\index{GLM} whenever the outcome is count. It also accommodates rate data\index{Rate data} as we will see shortly. Although count and rate data are very common in medical and health sciences, in our experience, Poisson regression\index{Poisson regression} is underutilized in medical research. Most often, researchers end up using linear regression because they are more familiar with it and lack of exposure to the advantage of using Poisson regression\index{Poisson regression} to handle count and rate data.

Count is discrete numerical data. Although it is convenient to use linear regression to handle the count outcome by assuming the count or _discrete_ numerical data (e.g. the number of hospital admissions) as _continuous_ numerical data (e.g. systolic blood pressure in mmHg), it may result in illogical predicted values. For example, by using linear regression to predict the number of asthmatic attacks in the past one year, we may end up with a negative number of attacks, which does not make any clinical sense! So, it is recommended that medical researchers get familiar with Poisson regression\index{Poisson regression} and make use of it whenever the outcome variable is a count variable.

Another reason for using Poisson regression\index{Poisson regression} is whenever the number of cases (e.g. deaths, accidents) is small relative to the number of no events (e.g. alive, no accident), then it makes more sense to just get the information from the cases in a population of interest, instead of also getting the information from the non-cases as in typical cohort and case-control studies. For example, in the publicly available COVID-19 data, only the number of deaths were reported along with some basic sociodemographic and clinical information for the cases. Whenever the information for the non-cases are available, it is quite easy to instead use logistic regression for the analysis.

Basically, Poisson regression\index{Poisson regression} models the linear relationship between:

- **outcome**: count variable (e.g. the number of hospital admissions, parity, cancerous lesions, asthmatic attacks). This is transformed into the natural log scale.
- **predictors/independent variables**: numerical variables (e.g. age, blood pressure, income) and categorical variables (e.g. gender, race, education level).

We might be interested in knowing the relationship between the number of asthmatic attacks in the past one year with sociodemographic factors. This relationship can be explored by a Poisson regression\index{Poisson regression} analysis. 

Basically, for Poisson regression\index{Poisson regression}, the relationship between the outcome and predictors is as follows,

$$\begin{aligned}
natural\ log\ of\ count\ outcome = &\ numerical\ predictors \\
& + categorical\ predictors
\end{aligned}$$

At times, the count is proportional to a denominator\index{Rate data}. For example, given the same number of deaths, the death rate in a small population will be higher than the rate in a large population. If we were to compare the the number of deaths between the populations, it would not make a fair comparison. Thus, we may consider adding denominators in the Poisson regression\index{Poisson regression} modelling in the forms of offsets. This denominator could also be the unit time of exposure, for example person-years of cigarette smoking. This will be explained later under Poisson regression\index{Poisson regression} for rate section.

In the previous chapter, we learned that logistic regression allows us to obtain the odds ratio\index{Odds ratio}, which is approximately the relative risk given a predictor. For Poisson regression\index{Poisson regression}, by taking the exponent of the coefficient, we obtain the _rate ratio_ RR\index{Rate ratio} (also known as _incidence rate ratio_ IRR\index{Incidence rate ratio}),

$$RR=exp(b_{p})$$
for the coefficient $b_p$ of the _p_'s predictor. This is interpreted in similar way to the odds ratio\index{Odds ratio} for logistic regression, which is approximately the relative risk given a predictor.

## Prepare R Environment for Analysis

### Libraries

For this chapter, we will be using the following packages:

- **tidyverse**\index{tidyverse}: a general and powerful package for data transformation
- **psych**\index{psych}: for descriptive statistics
- **gtsummary**\index{gtsummary}: for coming up with nice tables for results
- **broom**\index{broom}: for tidying up the results
- **epiDisplay**\index{epiDisplay}: an epidemiological data display package

These are loaded as follows using the function `library()`,
```{r, message=FALSE, error=FALSE}
library(tidyverse)
library(psych)
library(gtsummary)
library(broom)
```

For `epiDisplay`\index{epiDisplay}, we will use the package directly using `epiDisplay::function_name()` instead.
We did not load the package as we usually do with `library(epiDisplay)` because it has some conflicts with the packages we loaded above.

## Poisson regression\index{Poisson regression} for Count\index{Count data}

### About Poisson regression\index{Poisson regression} for count

Poisson regression\index{Poisson regression} models the linear relationship between:

- **outcome**: count variable (e.g. the number of hospital admissions, parity, cancerous lesions, asthmatic attacks). This is transformed into the natural log scale.
- **predictor(s)**: numerical variables (e.g. age, blood pressure, income) and categorical variables (e.g. gender, race, education level).

We might be interested in knowing the relationship between the number of asthmatic attacks in the past one year with sociodemographic factors. This relationship can be explored by a Poisson regression\index{Poisson regression} analysis. 

Multiple Poisson regression for count is given as,

$$\begin{aligned}
ln(count\ outcome) = &\ intercept \\
& + coefficients \times numerical\ predictors \\
& + coefficients \times categorical\ predictors
\end{aligned}$$

or in a shorter form,

$$ln(\hat y) = b_0 + b_1x_1 + b_2x_2 + ... + b_px_p$$
where we have _p_ predictors.

### Dataset

The data on the number of asthmatic attacks per year among a sample of 120 patients and the associated factors are given in `asthma.csv`.

The dataset contains four variables:

1. _gender_: Gender of the subjects (categorical) {male, female}.
2. _res_inf_: Recurrent respiratory infection (categorical) {no, yes}.
3. _ghq12_: General Health Questionnare 12 (GHQ-12) score of psychological well being (numerical) {0 to 36}.
4. _attack_: Number of athmatic attack per year (count).

The dataset is loaded as follows,
```{r}
asthma = read.csv("data/asthma.csv")
```

We then look at the basic structure of the dataset,
```{r}
str(asthma)
```

### Data exploration

For descriptive statistics, we introduce the `epidisplay` package\index{epiDisplay}. It is a nice package that allows us to easily obtain statistics for both numerical and categorical variables at the same time. We use `codebook()` function from the package.
```{r, message=FALSE}
epiDisplay::codebook(asthma)
```

### Univariable analysis

For the univariable analysis, we fit univariable Poisson regression models for gender (`gender`), recurrent respiratory infection (`res_inf`) and GHQ12 (`ghq12`) variables.
```{r}
# gender
pois_attack1 = glm(attack ~ gender, data = asthma, family = "poisson")
summary(pois_attack1)
# rec_res_inf
pois_attack2 = glm(attack ~ res_inf, data = asthma, family = "poisson")
summary(pois_attack2)
# ghq12
pois_attack3 = glm(attack ~ ghq12, data = asthma, family = "poisson")
summary(pois_attack3)
```
From the outputs, all variables are important with _P_ < .25. These variables are the candidates for inclusion in the multivariable analysis. However, as a reminder, in the context of **confirmatory research**\index{Confirmatory research}, the variables that we want to include must consider expert judgement\index{Expert judgement}.

### Multivariable analysis

For the multivariable analysis, we included all variables as predictors of `attack`. Here we use dot `.` as a shortcut for all variables when specifying the right-hand side of the formula of the `glm`.
```{r}
pois_attack_all = glm(attack ~ ., data = asthma, family = "poisson")
summary(pois_attack_all)
```
From the output, we noted that `gender` is not significant with _P_ > 0.05, although it was significant at the univariable analysis. Now, we fit a model excluding `gender`,
```{r}
# minus gender
pois_attack_all1 = glm(attack ~ res_inf + ghq12, data = asthma, 
                       family = "poisson")
summary(pois_attack_all1)
```
From the output, both variables are significant predictors of asthmatic attack (or more accurately the natural log of the count of asthmatic attack). This serves as our **preliminary model**.

### Interaction\index{Interaction}

Now, we include a two-way interaction\index{Interaction} term between `res_inf` and `ghq12`.
```{r}
pois_attack_allx = glm(attack ~ res_inf * ghq12, data = asthma, 
                       family = "poisson")
summary(pois_attack_allx)
```
It turns out that the interaction\index{Interaction} term `res_inf * ghq12` is significant. We may include this interaction\index{Interaction} term in the final model. However, this might complicate our interpretation of the result as we can no longer interpret individual coefficients. Given that the _P_-value of the interaction\index{Interaction} term is close to the commonly used significance level of 0.05, we may choose to ignore this interaction\index{Interaction}. But keep in mind that the decision is yours, the analyst. Having said that, if the purpose of modelling is mainly for prediction, the issue is less severe because we are more concerned with the predicted values than with the clinical interpretation of the result. However, if you insist on including the interaction\index{Interaction}, it can be done by writing down the equation for the model, substitute the value of `res_inf` with yes = 1 or no = 0, and obtain the coefficient for `ghq12`. We will see how to do this under **Presentation and interpretation** below.

### Model fit\index{Model fit} assessment

For Poisson regression\index{Poisson regression}, we assess the model fit\index{Model fit} by chi-square goodness-of-fit test, model-to-model AIC comparison and scaled Pearson chi-square statistic. We also assess the regression diagnostics\index{Regression diagnostics} using standardized residuals\index{Standardized residuals}.

#### Chi-square goodness-of-fit {-}

Chi-square goodness-of-fit test can be performed using `poisgof()` function in `epiDisplay` package\index{epiDisplay}. Note that, instead of using Pearson chi-square statistic, it utilizes residual deviance\index{Deviance} with its respective degrees of freedom (_df_) (e.g. from the output of `summary(pois_attack_all1)` above). A _P_-value > 0.05 indicates good model fit\index{Model fit}.
```{r}
epiDisplay::poisgof(pois_attack_all1)
```

#### Model-to-model AIC\index{AIC} comparison {-}

We may also compare the models that we fit so far by Akaike information criterion (AIC\index{AIC}). Recall that R uses AIC\index{AIC} for stepwise automatic variable selection\index{Variable selection}, which was explained in Linear Regression chapter.

```{r}
AIC(pois_attack1, pois_attack2, pois_attack3, 
    pois_attack_all1, pois_attack_allx)
```

The best model is the one with the lowest AIC\index{AIC}, which is the model model with the interaction\index{Interaction} term. However, since the model with the interaction\index{Interaction} term differ slightly from the model without interaction\index{Interaction}, we may instead choose the simpler model without the interaction\index{Interaction} term.

#### Scaled Pearson chi-square statistic {-}

Pearson chi-square statistic divided by its _df_ gives rise to scaled Pearson chi-square statistic [@fleiss2003]. The closer the value of this statistic to 1, the better is the model fit\index{Model fit}. First, Pearson chi-square statistic is calculated as,

$$\chi^2_P = \sum_{i=1}^n \frac{(y_i - \hat y_i)^2}{\hat y_i}$$
easily obtained in R as below.

```{r}
x2 = sum((asthma$attack - pois_attack_all1$fitted)^2 / 
           pois_attack_all1$fitted)
```

Then we obtain scaled Pearson chi-square statistic $\chi^2_P / df$, where $df = n - p$. $n$ is the number of observations `nrow(asthma)` and $p$ is the number of coefficients/parameters we estimated for the model `length(pois_attack_all1$coefficients)`.

```{r}
df = nrow(asthma) - length(pois_attack_all1$coefficients)
sx2 = x2 / df; sx2
```

The value of `sx2` is `r round(sx2, 3)`, which is close to 1. This indicates good model fit\index{Model fit}.

It is actually easier to obtain scaled Pearson chi-square by changing the `family = "poisson"` to `family = "quasipoisson"` in the `glm` specification, then viewing the `dispersion` value from the summary of the model. It works because scaled Pearson chi-square is an estimator of the overdispersion\index{Overdispersion} parameter in a quasi-Poisson regression\index{Quasi-Poisson regression} model [@fleiss2003]. We will discuss about quasi-Poisson regression\index{Quasi-Poisson regression} later towards the end of this chapter.

```{r}
qpois_attack_all1_summ = summary(glm(attack ~ res_inf + ghq12, 
                                     data = asthma, family = "quasipoisson"))
qpois_attack_all1_summ$dispersion
```

#### Regression diagnostics\index{Regression diagnostics} {-}

Here, we use standardized residuals\index{Standardized residuals} using `rstandard()` function. Because it is in form of standardized _z_ score, we may use specific cutoffs to find the outliers, for example 1.96 (for $\alpha$ = 0.05) or 3.89 (for $\alpha$ = 0.0001).

```{r}
std_res = rstandard(pois_attack_all1)
std_res[abs(std_res) > 1.96]
```

We now locate where the discrepancies are,

```{r}
index = names(std_res[abs(std_res) > 1.96])
cbind(asthma[index,], attack_pred = pois_attack_all1$fitted[index])
```

### Presentation and interpretation

#### Model without interaction\index{Interaction} {-}

After all these assumption check points, we decide on the final model and rename the model for easier reference.

```{r}
pois_attack_final = pois_attack_all1
```

We use `tbl_regression()` to come up with a table for the results. Here, for interpretation, we exponentiate the coefficients to obtain the incidence rate ratio, _IRR_.

```{r, message = FALSE, eval=FALSE}
tbl_regression(pois_attack_final, exponentiate = TRUE)
```

```{r, message = FALSE, echo=FALSE}
tbl_regression(pois_attack_final, exponentiate = TRUE) %>% as_gt()
```

Based on this table, we may interpret the results as follows:

- Those with recurrent respiratory infection are at higher risk of having an asthmatic attack with an IRR of 1.53 (95% CI: 1.14, 2.08), while controlling for the effect of GHQ-12 score.
- An increase in GHQ-12 score by one mark increases the risk of having an asthmatic attack by 1.05 (95% CI: 1.04, 1.07), while controlling for the effect of recurrent respiratory infection.

We can also view and save the output in a format suitable for exporting to the spreadsheet format for later use. We use `tidy()` function for the job,
```{r}
tib_pois_attack = tidy(pois_attack_final, exponentiate = TRUE, 
                       conf.int = TRUE)
tib_pois_attack
```

and export it to a `.csv` file,

```{r, eval=FALSE}
write.csv(tib_pois_attack, "tib_pois_attack.csv")
```

Then, we display the coefficients (i.e. without the exponent) and transfer the values into an equation,

```{r}
round(summary(pois_attack_final)$coefficients, 2)
```

$$\begin{aligned}
ln(attack) = & -0.34 + 0.43\times res\_inf + 0.05\times ghq12
\end{aligned}$$

From the table and equation above, the effect of an increase in GHQ-12 score is by one mark might not be clinically of interest. Let say, as a clinician we want to know the effect of an increase in GHQ-12 score by six marks instead, which is 1/6 of the maximum score of 36. From the coefficient for GHQ-12 of 0.05, the risk is calculated as

$$IRR_{GHQ12\ by\ 6} = exp(0.05\times 6) = 1.35$$

Or we may fit the model again with some adjustment to the data and `glm` specification. First, we divide `ghq12` values by 6 and save the values into a new variable `ghq12_by6`, followed by fitting the model again using the edited data set and new variable,

```{r}
# Divide ghq12 by 6
asthma_new = asthma %>% mutate(ghq12_by6 = ghq12 / 6)
# Fit the model
pois_attack_final_by6 = glm(attack ~ res_inf + ghq12_by6, 
                            data = asthma_new, family = "poisson")
```

Now we view the results for the re-fitted model,

```{r}
# coeffients
tidy(pois_attack_final_by6, conf.int = TRUE)
# IRRs
tidy(pois_attack_final_by6, exponentiate = TRUE, conf.int = TRUE)
```

As compared to the first method that requires multiplying the coefficient manually, the second method is preferable in R as we also get the 95% CI for `ghq12_by6`.

#### Model with interaction\index{Interaction} {-}

Now we will go through the interpretation of the model with interaction\index{Interaction}. We display the coefficients for the model with interaction\index{Interaction} (`pois_attack_allx`) and enter the values into an equation,

```{r}
round(summary(pois_attack_allx)$coefficients, 2)
```

$$\begin{aligned}
ln(attack) = & -0.34 + 0.43\times res\_inf + 0.05\times ghq12 \\
             & -0.03\times res\_inf\times ghq12
\end{aligned}$$

As we need to interpret the coefficient for `ghq12` by the status of `res_inf`, we write an equation for each `res_inf` status. When `res_inf` = 1 (yes),

$$\begin{aligned}
ln(attack) = & -0.63 + 1.02\times res\_inf + 0.07\times ghq12 \\
& -0.03\times res\_inf\times ghq12 \\
= & -0.63 + 1.02\times 1 + 0.07\times ghq12 -0.03\times 1\times ghq12 \\
= &\ 0.39 + 0.04\times ghq12
\end{aligned}$$

and when `res_inf` = 0 (no),

$$\begin{aligned}
ln(attack) = & -0.63 + 1.02\times res\_inf + 0.07\times ghq12 \\
& -0.03\times res\_inf\times ghq12 \\
= & -0.63 + 1.02\times 0 + 0.07\times ghq12 -0.03\times 0\times ghq12 \\
= & -0.63 + 0.07\times ghq12
\end{aligned}$$

Now, based on the equations, we may interpret the results as follows:

- For those with recurrent respiratory infection, an increase in GHQ-12 score by one mark increases the risk of having an asthmatic attack by 1.04 (IRR = exp[0.04]).
- For those without recurrent respiratory infection, an increase in GHQ-12 score by one mark increases the risk of having an asthmatic attack by 1.07 (IRR = exp[0.07]).

Based on these IRRs, the effect of an increase of GHQ-12 score is slightly higher for those without recurrent respiratory infection. However, in comparison to the IRR for an increase in GHQ-12 score by one mark in the model without interaction\index{Interaction}, with IRR = exp(0.05) = 1.05. So there are minimal differences in the IRR values for GHQ-12 between the models, thus in this case the simpler Poisson regression model without interaction\index{Interaction} is preferable. But now, you get the idea as to how to interpret the model with an interaction\index{Interaction} term.

### Prediction

We can use the final model above for prediction. Relevant to our data set, we may want to know the expected number of asthmatic attacks per year for a patient with recurrent respiratory infection and GHQ-12 score of 8,

```{r}
pred = predict(pois_attack_final, list(res_inf = "yes", ghq12 = 8), 
               type = "response")
round(pred, 1)
```

Now, let's say we want to know the expected number of asthmatic attacks per year for those with and without recurrent respiratory infection for each 12-mark increase in GHQ-12 score.

```{r}
new_data = data.frame(res_inf = rep(c("yes", "no"), each = 4),
                      ghq12 = rep(c(0, 12, 24, 36), 2))
new_data$attack_pred = round(predict(pois_attack_final, new_data, 
                                     type = "response"), 1)
new_data
```

## Poisson regression\index{Poisson regression} for Rate\index{Rate data}

### About Poisson regression\index{Poisson regression} for rate

At times, the count is proportional to a denominator. For example, given the same number of deaths, the death rate in a small population will be higher than the rate in a large population. If we were to compare the the number of deaths between the populations, it would not make a fair comparison. Thus, we may consider adding denominators in the Poisson regression\index{Poisson regression} modelling in form of offsets. This denominator could also be the unit time of exposure, for example person-years of cigarette smoking. 

As mentioned before, counts can be proportional specific denominators, giving rise to rates. We may add the denominators in the Poisson regression\index{Poisson regression} modelling as offsets. Again, these denominators could be stratum size or unit time of exposure. Multiple Poisson regression for rate is specified by adding the offset in the form of the natural log of the denominator $t$. This is given as,

$$ln(\hat y) = ln(t) + b_0 + b_1x_1 + b_2x_2 + ... + b_px_p$$

### Dataset

The data on the number of lung cancer cases among doctors, cigarettes per day, years of smoking and the respective person-years at risk of lung cancer are given in `smoke.csv`. The person-years variable serves as the offset for our analysis. The original data came from @Doll1971, which were analyzed in the context of Poisson regression by @Frome1983 and @fleiss2003. The dataset contains four variables:

1. _smoke_yrs_: Years of smoking (categorical) {15-19, 204-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59}.
2. _cigar_day_: Cigarettes per day (numerical).
3. _person_yrs_: Person-years at risk of lung cancer (numerical).
4. _case_: Number of lung cancer cases (count).

The dataset is loaded as follows,

```{r}
smoke = read.csv("data/smoke.csv")
```

Then, we look at its data structure,

```{r}
str(smoke)
```

### Data exploration

For descriptive statistics, we use `epidisplay::codebook` as before.

```{r, message=FALSE}
epiDisplay::codebook(smoke)
```

In addition, we are also interested to look at the observed rates,

```{r}
smoke %>% mutate(rate = round(case/person_yrs, 4))
```

### Univariable analysis

For the univariable analysis, we fit univariable Poisson regression models for cigarettes per day (`cigar_day`), and years of smoking (`smoke_yrs`) variables. Offset or denominator is included as `offset = log(person_yrs)` in the `glm` option.

```{r}
# cigar_day
pois_case1 = glm(case ~ cigar_day, data = smoke, family = "poisson", 
                 offset = log(person_yrs))
summary(pois_case1)
# smoke_yrs
pois_case2 = glm(case ~ smoke_yrs, data = smoke, family = "poisson", 
                 offset = log(person_yrs))
summary(pois_case2)
```

From the outputs, all variables including the dummy variables are important with _P_-values < .25.

### Multivariable analysis

For the multivariable analysis, we included `cigar_day` and `smoke_yrs` as predictors of `case`.

```{r}
pois_case = glm(case ~ cigar_day + smoke_yrs, data = smoke, 
                family = "poisson", offset = log(person_yrs))
summary(pois_case)
```

From the output, both variables are significant predictors of the rate of lung cancer cases, although we noted the _P_-values are not significant for `smoke_yrs20-24` and `smoke_yrs25-29` dummy variables. This model serves as our **preliminary model**.

### Interaction\index{Interaction}

Now, we include a two-way interaction\index{Interaction} term between `cigar_day` and `smoke_yrs`. From the output, although we noted that the interaction\index{Interaction} terms are not significant, the standard errors for `cigar_day` and the interaction\index{Interaction} terms are extremely large. This might point to a numerical issue with the model [@hosmer2013]. So, we may drop the interaction\index{Interaction} term from our model.

```{r}
pois_casex = glm(case ~ cigar_day * smoke_yrs, data = smoke,
                 family = "poisson", offset = log(person_yrs))
summary(pois_casex)
```

### Model fit\index{Model fit} assessment

Again, we assess the model fit\index{Model fit} by chi-square goodness-of-fit test, model-to-model AIC\index{AIC} comparison and scaled Pearson chi-square statistic and standardized residuals\index{Standardized residuals}.

```{r}
# Chi-square goodness-of-fit
epiDisplay::poisgof(pois_case)
```

The _P_-value of chi-square goodness-of-fit is more than 0.05, which indicates the model has good fit.

```{r}
# Model-to-model AIC comparison
AIC(pois_case1, pois_case2, pois_case)
```
The comparison by AIC\index{AIC} clearly shows that the multivariable model\index{Multivariable model} `pois_case` is the best model as it has the lowest AIC\index{AIC} value.

```{r}
# Scaled Pearson chi-square statistic using quasipoisson
qpois_case_summ = summary(glm(case ~ cigar_day + smoke_yrs, data = smoke, 
                              family = "quasipoisson", 
                              offset = log(person_yrs)))
qpois_case_summ$dispersion
```

The value of dispersion i.e. the scaled Pearson chi-square statistic is close to 1. This again indicates that the model has good fit.

```{r}
# Standardized residuals
std_res = rstandard(pois_case)
std_res[abs(std_res) > 1.96]
index = names(std_res[abs(std_res) > 1.96])
# points of discrepancies
cbind(smoke[index,], case_pred = pois_case$fitted[index]) %>%
  mutate(rate = round(case/person_yrs, 4), 
         rate_pred = round(case_pred/person_yrs, 4))
```

Lastly, we noted only a few observations (number 6, 8 and 18) have discrepancies between the observed and predicted cases. This shows how well the fitted Poisson regression model for rate explains the data at hand.

### Presentation and interpretation

Now, we decide on the final model,

```{r}
pois_case_final = pois_case
```
and use `tbl_regression()` to come up with a table for the results. Again, for interpretation, we exponentiate the coefficients to obtain the incidence rate ratio, _IRR_\index{Incidence rate ratio}\index{Rate ratio}.

```{r, message = FALSE, eval=FALSE}
tbl_regression(pois_case_final, exponentiate = TRUE)
```

```{r, message = FALSE, echo=FALSE}
tbl_regression(pois_case_final, exponentiate = TRUE) %>% as_gt()
```

From this table, we interpret the IRR values as follows:

- Taking an additional cigarette per day increases the risk of having lung cancer by 1.07 (95% CI: 1.05, 1.08), while controlling for the other variables.
- Those who had been smoking for between 30 to 34 years are at higher risk of having lung cancer with an IRR of 24.7 (95% CI: 5.23, 442), while controlling for the other variables.

We leave the rest of the IRRs for you to interpret. But take note that the IRRs for years of smoking (`smoke_yrs`) between `30-34` to `55-59` categories are quite large with wide 95% CIs, although this does not seem to be a problem since the standard errors are reasonable for the estimated coefficients (look again at `summary(pois_case)`). The 95% CIs for `20-24` and `25-29` include 1 (which means no risk) with risks ranging from lower risk (IRR < 1) to higher risk (IRR > 1). This is expected because the _P_-values for these two categories are not significant.


Then, we view and save the output in the spreadsheet format for later use. We use `tidy()`,

```{r}
tib_pois_case = tidy(pois_case_final, exponentiate = TRUE, 
                     conf.int = TRUE)
tib_pois_case
```

and export it to a `.csv` file,

```{r, eval=FALSE}
write.csv(tib_pois_case, "tib_pois_case.csv")
```

Now, we present the model equation, which unfortunately this time quite a lengthy one. We display the coefficients,

```{r}
round(summary(pois_case_final)$coefficients, 2)
```

and put the values in the equation. Remember to include the offset in the equation.

$$\begin{aligned}
ln(case) = &\ ln(person\_yrs) -11.32 + 0.06\times cigar\_day \\
& + 0.96\times smoke\_yrs(20-24) + 1.71\times smoke\_yrs(25-29) \\
& + 3.21\times smoke\_yrs(30-34) + 3.24\times smoke\_yrs(35-39) \\
& + 4.21\times smoke\_yrs(40-44) + 4.45\times smoke\_yrs(45-49) \\
& + 4.89\times smoke\_yrs(50-54) + 5.37\times smoke\_yrs(55-59)
\end{aligned}$$

## Quasi-Poisson Regression\index{Quasi-Poisson regression} for Overdispersed Data\index{Overdispersed data}

We utilized `family = "quasipoisson"` option in the `glm` specification before just to easily obtain the scaled Pearson chi-square statistic without knowing what it is. So, what is a quasi-Poisson regression?\index{Quasi-Poisson regression} For a typical Poisson regression analysis, we rely on maximum likelihood estimation method. It assumes that the mean (of the count) and its variance are equal, or variance divided by mean equals 1. For that reason, we expect that scaled Pearson chi-square statistic to be close to 1 so as to indicate good fit of the Poisson regression model.

So what if this assumption of "mean equals variance" is violated? Whenever the variance is larger than the mean for that model, we call this issue _overdispersion_\index{Overdispersion}. In particular, it will affect a Poisson regression model by underestimating the standard errors of the coefficients. So, we may have narrower confidence intervals and smaller _P_-values (i.e. more likely to have false positive results) than what we could have obtained. In handling the overdispersion\index{Overdispersion} issue, one may use a negative binomial regression, which we do not cover in this book. A more flexible option is by using quasi-Poisson regression\index{Quasi-Poisson regression} that relies on quasi-likelihood estimation method [@fleiss2003].

To demonstrate a quasi-Poisson regression\index{Quasi-Poisson regression} is not difficult because we already did that before when we wanted to obtain scaled Pearson chi-square statistic before in the previous sections. As an example, we repeat the same using the model for count. We fit the standard Poisson regression model,

```{r}
pois_attack_all1 = glm(attack ~ ., data = asthma, family = "poisson")
```

Then we fit the same model using quasi-Poisson regression\index{Quasi-Poisson regression},

```{r}
qpois_attack_all1 = glm(attack ~ ., data = asthma, 
                        family = "quasipoisson")
```

Now, pay attention to the standard errors and confidence intervals of each models. Can you spot the differences between the two? (Hints: `std.error`, `p.value`, `conf.low` and `conf.high` columns).

```{r}
# Poisson
tidy(pois_attack_all1, conf.int = TRUE)
# quasi-Poisson
tidy(qpois_attack_all1, conf.int = TRUE)  
```

Note that there are no changes to the coefficients between the standard Poisson regression and the quasi-Poisson regression\index{Quasi-Poisson regression}. We also interpret the quasi-Poisson regression\index{Quasi-Poisson regression} model output in the same way to that of the standard Poisson regression model output.

## Summary

In this chapter, we went through the basics about Poisson regression\index{Poisson regression} for count\index{Count data} and rate data\index{Rate data}. We performed the analysis for each and learned how to assess the model fit\index{Model fit} for the regression models. We learned how to nicely present and interpret the results. In addition, we also learned how to utilize the model for prediction.To understand more about the concep, analysis workflow and interpretation of count data analysis including Poisson regression, we recommend texts from the Epidemiology: Study Design and Data Analysis book [@woodward2013epidemiology] and Regression Models for Categorical Dependent Variables Using Stata book [@long2006regression]. 

