---
output:
  pdf_document: default
---

# Survival analysis



## Packages

To run the tutorial, we will use 

- **survival**: This is a package necessary to run survival analysis. There are other survival packages that can run survival analysis which you can find here <https://cran.r-project.org/web/views/Survival.html>
- **survminer**: a package to plot survival objects
- **pec**: a package to use a breast cancer dataset
- **tidyverse**: a package for data transformation
- **broom**: to make prettier outputs
- **here** to manage location fo files

Remember, check if all packages are available in your R library. If you have not installed them, use `install.packages()` function to download and install the packages. 

Note: If or once the packages are already installed, then load the package

```{r}
library(survival)
library(survminer)
library(pec)
library(tidyverse)
library(broom)
library(here)
```


## Data

The tutorial uses a dataset named *stroke_dat* in a csv format. 

Now let us load the data 

```{r}
stroke_dat <- read_csv(here('data', 'stroke_data.csv'))
```

And take a peek at our data

```{r}
glimpse(stroke_dat)
```

And summary statistics are

```{r}
summary(stroke_dat)
```


To be able to perform survival analysis, the dataset has this time-to-event variable

1.  time : a time variable indicates days taken from the first day the patient was enrolled in the study until the last seen  
2.  an event variable : a status variable for the patient when he or she was last seen  

So, it is a time-to-event dataset. There are other variables too for example

- sex:  
- referral: 
- dm:
- gcs:
- sbp:
- dbp: 
- wbc:
- str_type2:
- referral2:

In the dataset: 

1.  variable time *time* was a numeric variable measured in days
2.  variable event *event*  was a categorical variable coded as alive or dead


*stroke_dta* data is an object of *tibble* class. 

```{r}
class(stroke_dat)
```

## Exploratory data   

The distribution of stroke types 

```{r}
stroke_dat %>% group_by(status) %>% count()
stroke_dat %>% group_by(status, str_type2) %>% count()
```

The descriptive statistics for 


```{r}
stroke_dat %>% filter(status == 'alive') %>% 
  dplyr::select(gcs, sbp, dbp, wbc, time2) %>% 
  summary()
```


## Kaplan-Meier survival estimates 

### Estimate the KM survivals 


This is a non-parametric survival estimates. It provides the survival probability estimates at different time.  

## Survival probability

Kaplan-Meier (KM) is a non-parametric survival analysis. Using `survfit()`, we will estimate the survival probability using the Kaplan-Meier (KM) estimates. We will estimate KM for stroke types.  
And the result will be named `KM_str_type2`


```{r}
KM_str_type2 <- survfit(Surv(time = time2, event = status == "dead" ) ~ str_type2, 
                        data = stroke_dat)
summary(KM_str_type2)
```

## Plot the survival probability  

We will plot the survival probability based on the KM estimate.

The plot provides

1.  y axis: survival probability
2.  x axis: time

```{r}
ggsurvplot(KM_str_type2, data = stroke_dat, risk.table = TRUE, 
           linetype = c(1,4), pval = TRUE)
```

Run the Kaplan-Meier estimates for variable dm and named the output as KM_dm

```{r}
KM_dm <- survfit(Surv(time = time2, event = status == "dead" ) ~ dm, 
                        data = stroke_dat)
summary(KM_dm)
```

Plot the survival estimates

```{r}
ggsurvplot(KM_dm, data = stroke_dat, risk.table = TRUE, 
           linetype = c(1,4), pval = TRUE)
```

## Comparing survival estimates from Kaplan-Meier analysis 

### Log-rank test

Plotting Kaplan-Meier survival curves provides graphical representation of survival probabilities in different group. 

The question is : Do the survival estimates differ between different levels (groups)?

To answer, we test the null hypothesis that the survival times between levels in variable *group* are similar.

A few available tests, for example:

1.  log-rank test (default)
2.  peto-peto test

```{r}
survdiff(Surv(time = time2, event = status == "dead") ~ str_type2, data = stroke_dat)
```

The survival times between the stroke types *IS* and *HS* groups are different (p = 0.014). 

```{r}
survdiff(Surv(time = time2, event = status == "dead") ~ dm, data = stroke_dat)
```

The survival times between the dm status *yes* and *no* groups are not different (p = 0.2). 

## Cox proportional hazard regression

### Advantages of Cox proportional hazard regression

The disadvantages of the Kaplan-Meier (KM) analysis include these:

1.  The need to categorize numerical variable
2.  It is a univariable analysis
3.  It is a non-parametric analysis


To overcome the limitations of the KM analysis, we can model our survival data using the semi-parametric **Cox proportional hazard regression**. 

We will use **Breast cancer survival data (GBSG2)** from **pec** package

Load the *GBSG2* data

```{r}
data(GBSG2)
```

Take a peek at data

```{r}
glimpse(GBSG2)
```

Get the summary statistics

```{r}
summary(GBSG2)
```

In the dataset (686 observations):

1.  the time variable: *time* (days)
2.  the event variable: *cens* (coded as 1 vs 0). The event of interest is 1 and censored cases (for example, loss to follow up) is 0. 

299 developed the event (n = 299)

```{r}
table(GBSG2$cens)
```

Let us convert the `cens` (0 and 1) variable to 

1.  a variable named `event`
2.  and code *failed* for 1, and *censored* for 0

```{r}
str(GBSG2$cens)
GBSG2 <- GBSG2 %>% mutate(event = factor(cens, 
                                         labels =  c("censored", "failed")))
table(GBSG2$event)
```


## Estimation of Cox proportional hazards regression

We will run a generalized linear model using Cox PH regression with

1.  time variable *time*
2.  event variable *event == "failed"*
3.  all covariates 

This becomes a multivariable Cox PH model


```{r}
GBSG2_coxph <- coxph(Surv(time = time, event = event == 'failed') ~ .,
                     data = GBSG2)
summary(GBSG2_coxph)
```

The results:

1.  The `coef` is the log hazard. 
2.  And the `exp(coef)` is hazard ratio. 

Interpretation: 

1.  Each 1 unit increase in **progrec**, the adjusted log hazard for dying change by -0.002. So, with 10 units increase in **progrec**, the adjusted log hazard for dying change by -0.02
2.  Each 1 unit increase in **progrec**, the adjusted rate for hazard or the risk for dying changed by 0.998. Or similarly, the risk for dying with 1 unit increase in **progrec**reduces by 0.2%.

## Inference from Cox proportional hazard regression

To do inference, we estimate

1.  the Wald test. This is shown with p-values in the example above
2.  the 95% confidence intervals for the log hazards

```{r}
# the confidence intervals for log hazards
ci <- confint(GBSG2_coxph)
ci
```

We can transform log hazard to hazard ratio by exp the $\hat\beta$. It is more interesting for applied scientists to make inferences based on the 95% CI of the hazard ratios

```{r}
# hazard ratios and the corresponding confidence intervals 
exp(cbind(coef(GBSG2_coxph), ci))
```

This result implies that:

1.  patients treated with a hormonal therapy (`horThyes`) had a lower
risk ($29\%$ lower) to die. Thus they survived longer compared to women who were not treated this
way 
2.  the risk for dying for patients treated with a hormonal therapy (`horThyes`) can be as small as $9\%$ or as big as $45\%$ at $95\%$ confidence levels.  

## **tidy()** for nicer output

`broom::tidy` can give nicer outputs

```{r}
broom::tidy(GBSG2_coxph)
```

and to get the *hazard ratios*

```{r}
broom::tidy(GBSG2_coxph, exponentiate = TRUE)
```

## Prediction

We can predict

1.  the linear predictor
2.  the risk (risk score exp(lp))
3.  the he expected number of events given the covariates and follow-up time

```{r}
library(broom)
lp <- augment(GBSG2_coxph, data = GBSG2)
risks <- augment(GBSG2_coxph, data = GBSG2, type.predict = "risk")
expected <- augment(GBSG2_coxph, data = GBSG2, type.predict = "expected")
```

We can also plot the survival

```{r}
mod_coxph <- coxph(Surv(time = time, event = event == 'failed') ~ horTh + age + tgrade, data = GBSG2)
ggadjustedcurves(mod_coxph, data = GBSG2)
ggadjustedcurves(mod_coxph, data = GBSG2, variable = "horTh")
ggadjustedcurves(mod_coxph, data = GBSG2, method = "average", variable = "horTh")
```


## Checking the proportional hazard assumption

### Proportional hazard assumption

The most important assumption in Cox PH regression is the proportionality of the hazards over time.

A check of the proportional hazards assumption can be done by looking at the parameter estimates $\beta_1, ..., \beta_q$ over time. 

We can safely assume proportional hazards when the estimates don't vary much over time. 

The null hypothesis of constant regression coefficients can be tested, both globally as well as for each covariate, by using the cox.zph function.


```{r}
#GBSG2_zph <- cox.zph(GBSG2_coxph)
#GBSG2_zph
```

Evidence of time-varying effects (non-proportionality), especially for age (p = 0.0855)
and tumor grading. But we keep at this for now. Because this requires a more advanced method.

So basically, if the GLOBAL test gives non-significant (p> 0.05), the assumption of proportional hazard is met. if it is less than 0.05, we need to remedial measures. 

We can plot the log hazard over time, to see the performance of our model (in terms of proportionality)

```{r}
# plot(GBSG2_zph, var = "age")
# plot(GBSG2_zph, var = "tgradeIII")
# plot(GBSG2_zph, var = "menostatPre")
# plot(GBSG2_zph, var = "progrec")
# plot(GBSG2_zph, var = "horThyes")


```

For now, we will assume the proportionality of hazard is acceptable. In the case of serious violation of proportionality of hazard, we can remedy using 

1.  stratified cox regression
2.  extended cox regression using time-varying dependent variable
3.  parametric survival analysis


## References

This will be a brief practical note on running survival analysis in R. 

Parts of this note are taken from this source  <http://ftp.auckland.ac.nz/software/CRAN/doc/vignettes/HSAUR/Ch_survival_analysis.pdf>. The source comes from the book entitled A Handbook of Statistical Analyses Using R - and if you are interested - the book can be bought here <https://www.amazon.com/Handbook-Statistical-Analyses-Using-Second/dp/1420079336>